{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install gradio peft","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:46:52.645666Z","iopub.execute_input":"2023-09-14T15:46:52.646361Z","iopub.status.idle":"2023-09-14T15:47:13.249500Z","shell.execute_reply.started":"2023-09-14T15:46:52.646311Z","shell.execute_reply":"2023-09-14T15:47:13.248426Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-3.44.2-py3-none-any.whl (20.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.1.1)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.98.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.5.0 (from gradio)\n  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from gradio)\n  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.16.4)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.12.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.2)\nRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.0.2)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.10.9)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart (from gradio)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.31.0)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.6.3)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (11.0.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.5.0->gradio) (2023.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.33.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\nCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.1)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=d630905bb9070b43d30bb5f82d81bcc6794b4ae6570f55cf95c7feeaf984d471\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, semantic-version, python-multipart, httpcore, httpx, peft, gradio-client, gradio\nSuccessfully installed ffmpy-0.3.1 gradio-3.44.2 gradio-client-0.5.0 httpcore-0.18.0 httpx-0.25.0 peft-0.5.0 python-multipart-0.0.6 semantic-version-2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:01:12.068425Z","iopub.execute_input":"2023-09-14T16:01:12.069091Z","iopub.status.idle":"2023-09-14T16:01:17.385170Z","shell.execute_reply.started":"2023-09-14T16:01:12.069051Z","shell.execute_reply":"2023-09-14T16:01:17.384170Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:02:39.523415Z","iopub.execute_input":"2023-09-14T16:02:39.523849Z","iopub.status.idle":"2023-09-14T16:02:39.533470Z","shell.execute_reply.started":"2023-09-14T16:02:39.523815Z","shell.execute_reply":"2023-09-14T16:02:39.532453Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"torch.set_default_device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:07:24.944977Z","iopub.execute_input":"2023-09-14T16:07:24.945422Z","iopub.status.idle":"2023-09-14T16:07:24.952318Z","shell.execute_reply.started":"2023-09-14T16:07:24.945387Z","shell.execute_reply":"2023-09-14T16:07:24.950987Z"},"editable":false,"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import AutoTokenizer\nimport re\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig\nimport torch\n\nconfig = PeftConfig.from_pretrained(\"mohamedemam/Arabic-meeting-summarization\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-3b\",quantization_config=bnb_config)\nmodel = PeftModel.from_pretrained(model, \"mohamedemam/Arabic-meeting-summarization\")\n# Load the tokenizer and model\nmodel_name =\"bigscience/bloomz-3b\"\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-3b\")\nmodel.eval()\n\n# Function to generate questions and answers with configurable parameters\ndef generate_qa(context, temperature, top_p,num_seq,l_p, num_b):\n    input_text = context\n    input_ids = tokenizer(text=input_text, return_tensors='pt')\n    \n    # Generate with configurable parameters\n    output = model.generate(\n        **input_ids,\n        temperature=temperature,\n        top_p=top_p,\n        num_return_sequences=num_seq,\n   \n        max_new_tokens=60,\n        num_beams=num_b,\n        length_penalty=l_p,    \n        do_sample=True,\n        \n    )\n    #\n    generated_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n\n    formatted_output = \"\\n\\n\".join(set(generated_text))\n    return formatted_output\niface = gr.Interface(\n    fn=generate_qa,\n    inputs=[\n        gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n        gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),     \n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"), \n        gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n     ,\n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n\n\n    ],\n    outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n    title=\"Question Generation and Answering\",\n    description=\"Select an example context, choose a recommended word, adjust temperature and top-p. The model will generate questions and answers.\",\n)\n# Launch the interface\niface.launch()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:32:37.706423Z","iopub.execute_input":"2023-09-14T16:32:37.707481Z","iopub.status.idle":"2023-09-14T16:32:41.845140Z","shell.execute_reply.started":"2023-09-14T16:32:37.707429Z","shell.execute_reply":"2023-09-14T16:32:41.843713Z"},"jupyter":{"source_hidden":true},"editable":false,"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"    a = tokenizer(text=\"as\", return_tensors='pt')\n    \n    # Generate with configurable parameters\n    output = model.generate(input_ids= a['input_ids'].cuda(),\n        temperature=1.2,\n        top_p=.3,\n        num_return_sequences=2,\n        max_new_tokens=60,\n        num_beams=3,\n        length_penalty=1,    \n        do_sample=True,\n        \n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:15:43.922280Z","iopub.execute_input":"2023-09-14T16:15:43.922731Z","iopub.status.idle":"2023-09-14T16:15:50.204650Z","shell.execute_reply.started":"2023-09-14T16:15:43.922700Z","shell.execute_reply":"2023-09-14T16:15:50.203572Z"},"editable":false,"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"w=\"\"\ndef generate_qa(context, temperature, top_p,num_seq,l_p, num_b):\n    input_text = f\"{context}\"+f\"\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n\"\n    input_ids = tokenizer(text=input_text, return_tensors='pt')\n    global w\n    w=input_text\n    # Generate with configurable parameters\n    output = model.generate(\n        input_ids=input_ids['input_ids'].cuda(),\n        temperature=temperature,\n        top_p=top_p,\n        num_return_sequences=num_seq,\n   \n        max_new_tokens=60,\n        num_beams=num_b,\n        length_penalty=l_p,    \n        do_sample=True,\n        \n    )\n    \n    #\n    generated_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n\n    formatted_output = \"\\n\\n\".join(set(generated_text))\n    return formatted_output","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:37:36.270448Z","iopub.execute_input":"2023-09-14T16:37:36.270870Z","iopub.status.idle":"2023-09-14T16:37:36.279238Z","shell.execute_reply.started":"2023-09-14T16:37:36.270836Z","shell.execute_reply":"2023-09-14T16:37:36.278220Z"},"editable":false,"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\niface = gr.Interface(\n    fn=generate_qa,\n    inputs=[\n        \"text\",\n        gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n        gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),     \n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"), \n        gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n     ,\n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n\n\n    ],\n    outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n    title=\"Question Generation and Answering\",\n    description=\"Select an example context, choose a recommended word, adjust temperature and top-p. The model will generate questions and answers.\",\n)\n# Launch the interface\niface.launch()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:37:36.972293Z","iopub.execute_input":"2023-09-14T16:37:36.972691Z","iopub.status.idle":"2023-09-14T16:37:45.505645Z","shell.execute_reply.started":"2023-09-14T16:37:36.972659Z","shell.execute_reply":"2023-09-14T16:37:45.504668Z"},"editable":false,"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_94/1303577419.py:5: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n/tmp/ipykernel_94/1303577419.py:5: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n/tmp/ipykernel_94/1303577419.py:6: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),\n/tmp/ipykernel_94/1303577419.py:6: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),\n/tmp/ipykernel_94/1303577419.py:7: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"),\n/tmp/ipykernel_94/1303577419.py:7: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"),\n/tmp/ipykernel_94/1303577419.py:8: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n/tmp/ipykernel_94/1303577419.py:8: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n/tmp/ipykernel_94/1303577419.py:10: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n/tmp/ipykernel_94/1303577419.py:10: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n/tmp/ipykernel_94/1303577419.py:14: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n","output_type":"stream"},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7869\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://b2c8cfc5855ddb5f9b.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://b2c8cfc5855ddb5f9b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"w","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:38:00.463359Z","iopub.execute_input":"2023-09-14T16:38:00.463800Z","iopub.status.idle":"2023-09-14T16:38:00.471235Z","shell.execute_reply.started":"2023-09-14T16:38:00.463768Z","shell.execute_reply":"2023-09-14T16:38:00.470208Z"},"editable":false,"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'مرحبًا، أنا ديفيد ومن المفترض أن أكون مصممًا صناعيًا. أم، لقد حصلت للتو على إعلان المشروع حول ماهية المشروع. تصميم جهاز التحكم عن بعد. هذا كل ما في الأمر، ولم أحصل على أي شيء آخر. هل حصلت على نفس الشيء؟ رائع. هناك الكثير من العتاد. تمام. لا أستطيع الرسم. أم. نعم. حسنًا على أية حال، لا أعرف، إنه أول حيوان يمكنني التفكير فيه من أعلى رأسي. أم. نعم. السبب الرئيسي هو أنني أشعر بالحساسية تجاه معظم الحيوانات. حساسية من فراء الحيوانات، لذلك كانت الأسماك خيارًا طبيعيًا. أم، نعم، وأنا أحب الحيتان نوعًا ما. يأتون ويذهبون ويأكلون كل شيء في الأفق. وهي غير ضارة تمامًا وخفيفة ومثيرة للاهتمام. الذيل كبير بعض الشيء، على ما أعتقد. إنه كلب بعد العشاء إذن. همم. ربما يكون هذا منطقيًا من وجهة نظر التصميم، لأنه لديك أحرف أكثر تعقيدًا مثل اللغات الأوروبية، فأنت بحاجة إلى المزيد من الأزرار. لذلك، ربما. همم. نعم. وتستمر في خسارتهم. العثور عليهم أمر مؤلم حقًا، كما تعلمون. أعني أنها عادة ما تكون صغيرة جدًا، أو عندما تريدها بشكل صحيح، تنزلق خلف الأريكة أو يتم ركلها تحت الطاولة. أنت تعرف. نعم. مم-هممم. أعتقد أن أحد العوامل سيكون تكلفة الإنتاج. نظرًا لوجود حد أقصى هناك، لذا يعتمد الأمر على المبلغ الذي يمكنك حشره في هذا السعر. أم. أعتقد أن هذا هو العامل الرئيسي. رائع.\\n\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T11:44:47.646794Z","iopub.execute_input":"2023-09-14T11:44:47.647077Z","iopub.status.idle":"2023-09-14T11:44:47.994751Z","shell.execute_reply.started":"2023-09-14T11:44:47.647044Z","shell.execute_reply":"2023-09-14T11:44:47.993835Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:59:01.666941Z","iopub.execute_input":"2023-09-14T15:59:01.667352Z","iopub.status.idle":"2023-09-14T15:59:18.833012Z","shell.execute_reply.started":"2023-09-14T15:59:01.667317Z","shell.execute_reply":"2023-09-14T15:59:18.831688Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.41.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/transformers.git ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:59:18.836910Z","iopub.execute_input":"2023-09-14T15:59:18.837253Z","iopub.status.idle":"2023-09-14T16:00:05.598966Z","shell.execute_reply.started":"2023-09-14T15:59:18.837218Z","shell.execute_reply":"2023-09-14T16:00:05.597767Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-18b1g5zp\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-18b1g5zp\n  Resolved https://github.com/huggingface/transformers.git to commit 44a0490d3c46e62134b3fc1f0609cbdf83e571da\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.34.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (2023.7.22)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7662134 sha256=36a9b38770edeb9d3ceebf6f3a28bec5422137799c511d9407f56c77428f20ac\n  Stored in directory: /tmp/pip-ephem-wheel-cache-h_telic9/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\nSuccessfully installed transformers-4.34.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/peft.git\n!pip install  -U git+https://github.com/huggingface/accelerate.git\n!pip install  datasets","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:00:05.600636Z","iopub.execute_input":"2023-09-14T16:00:05.601038Z","iopub.status.idle":"2023-09-14T16:01:12.065760Z","shell.execute_reply.started":"2023-09-14T16:00:05.601000Z","shell.execute_reply":"2023-09-14T16:01:12.064580Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/peft.git\n  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-p7n3nssw\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-p7n3nssw\n  Resolved https://github.com/huggingface/peft.git to commit 93d0c03d5ba6b2a6b16b7ca887e740a67bc680f3\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.34.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (0.3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.6.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->peft==0.6.0.dev0) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.6.0.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.6.0.dev0) (1.3.0)\nBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=107812 sha256=d83f766d5ce6ca0c04f8ee7f90fd6585fddd40d4e1adb69ba2675e63c389cb43\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rkpsim6r/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\nSuccessfully built peft\nInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.5.0\n    Uninstalling peft-0.5.0:\n      Successfully uninstalled peft-0.5.0\nSuccessfully installed peft-0.6.0.dev0\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-hq6ehyc7\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-hq6ehyc7\n  Resolved https://github.com/huggingface/accelerate.git to commit bbcdbbaffc2f0d5619f0e16c90a4c8b7e088c27f\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.23.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.23.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.23.0.dev0-py3-none-any.whl size=258131 sha256=00f1a14f4e3da8ef08ba251815f79d95217a83dadbc9fa5ddeb4786f6635c850\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dt8dhfuz/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed accelerate-0.23.0.dev0\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:44:54.819074Z","iopub.execute_input":"2023-09-14T16:44:54.819792Z","iopub.status.idle":"2023-09-14T16:44:54.825201Z","shell.execute_reply.started":"2023-09-14T16:44:54.819757Z","shell.execute_reply":"2023-09-14T16:44:54.824209Z"},"editable":false,"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:44:55.076047Z","iopub.execute_input":"2023-09-14T16:44:55.076977Z","iopub.status.idle":"2023-09-14T16:44:55.926983Z","shell.execute_reply.started":"2023-09-14T16:44:55.076946Z","shell.execute_reply":"2023-09-14T16:44:55.925900Z"},"editable":false,"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data.iloc[1221,3]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:47:54.897568Z","iopub.execute_input":"2023-09-14T16:47:54.897949Z","iopub.status.idle":"2023-09-14T16:47:54.904605Z","shell.execute_reply.started":"2023-09-14T16:47:54.897919Z","shell.execute_reply":"2023-09-14T16:47:54.903587Z"},"editable":false,"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'إميلي: 👻\\n إميلي: مرحبا.هل تشعر بالرغبة في تناول العشاء في ناندو الليلة؟\\n إميلي: يمكنني حجز طاولة\\n باكو: بالتأكيد ، اذهب إليها\\n مايكل: نعم من فضلك.أنا على وشك أخذ الأنبوب إلى المنزل الآن\\n مايكل: أرغب في الاستحمام قبل الخروج ، هل يمكنك حجز الجدول ، على سبيل المثال ، 8 مساءً؟\\n إميلي: بالتأكيد ، لا مشكلة\\n مايكل: أراك قريبًا على أي حال\\n إميلي: بارد\\n باكو: 👌'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-3b\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-3b\",quantization_config=nf4_config,)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:47:19.607055Z","iopub.execute_input":"2023-09-14T11:47:19.607571Z","iopub.status.idle":"2023-09-14T11:48:17.397613Z","shell.execute_reply.started":"2023-09-14T11:47:19.607537Z","shell.execute_reply":"2023-09-14T11:48:17.396620Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/199 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500f7bb1c3c343d5b54e9baf9982ab77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f885e8b0286a4806883956681aabd6b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a953611c017c400ea9fdb53b45d16e6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2201e32db143b193a717352150d6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/6.01G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1147a4a4aaae40a98f974ceb2890e155"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install peft","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:48:17.398966Z","iopub.execute_input":"2023-09-14T11:48:17.399581Z","iopub.status.idle":"2023-09-14T11:48:30.099403Z","shell.execute_reply.started":"2023-09-14T11:48:17.399546Z","shell.execute_reply":"2023-09-14T11:48:30.098071Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.0.dev0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.34.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.0.dev0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=4, \n    lora_alpha=16, \n            target_modules=[\"query_key_value\"],\n\n    lora_dropout=0.05, \n    bias=\"none\", \n    \n    task_type=\"CAUSAL_LM\"\n)\n#model = get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:49:25.663516Z","iopub.execute_input":"2023-09-14T11:49:25.663950Z","iopub.status.idle":"2023-09-14T11:49:25.710886Z","shell.execute_reply.started":"2023-09-14T11:49:25.663915Z","shell.execute_reply":"2023-09-14T11:49:25.709855Z"},"editable":false,"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from peft import AutoPeftModel,PeftModel","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:52:36.837825Z","iopub.execute_input":"2023-09-14T11:52:36.838230Z","iopub.status.idle":"2023-09-14T11:52:36.843083Z","shell.execute_reply.started":"2023-09-14T11:52:36.838198Z","shell.execute_reply":"2023-09-14T11:52:36.842158Z"},"editable":false,"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"a=PeftModel.from_pretrained(model,\"/kaggle/input/blooma/results_modified/checkpoint-800\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:04.463466Z","iopub.execute_input":"2023-09-14T11:53:04.463854Z","iopub.status.idle":"2023-09-14T11:53:09.809405Z","shell.execute_reply.started":"2023-09-14T11:53:04.463823Z","shell.execute_reply":"2023-09-14T11:53:09.808439Z"},"editable":false,"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:09.811266Z","iopub.execute_input":"2023-09-14T11:53:09.811601Z","iopub.status.idle":"2023-09-14T11:53:10.606730Z","shell.execute_reply.started":"2023-09-14T11:53:09.811570Z","shell.execute_reply":"2023-09-14T11:53:10.605760Z"},"editable":false,"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:10.608087Z","iopub.execute_input":"2023-09-14T11:53:10.608439Z","iopub.status.idle":"2023-09-14T11:53:10.613659Z","shell.execute_reply.started":"2023-09-14T11:53:10.608407Z","shell.execute_reply":"2023-09-14T11:53:10.612744Z"},"editable":false,"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        a = tokenizer( (data['dialogue']+data['summary']).tolist(), truncation=True, padding='max_length', return_tensors=\"pt\", max_length=512)\n        self.dataset=  [\n            {\n            \n                            \"input_ids\":inputs,\n                            \"attention_mask\": att,\n                            \"labels\":inputs\n                        } \n                            for inputs,att in zip(a['input_ids'],a['attention_mask'])\n        ]\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return self.dataset[idx]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:10.615979Z","iopub.execute_input":"2023-09-14T11:53:10.617020Z","iopub.status.idle":"2023-09-14T11:53:10.630924Z","shell.execute_reply.started":"2023-09-14T11:53:10.616969Z","shell.execute_reply":"2023-09-14T11:53:10.629948Z"},"editable":false,"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'class SummarizationDataset(Dataset):\\n    def __init__(self, tokenized_dataset):\\n        a = tokenizer( (data[\\'dialogue\\']+data[\\'summary\\']).tolist(), truncation=True, padding=\\'max_length\\', return_tensors=\"pt\", max_length=512)\\n        self.dataset=  [\\n            {\\n            \\n                            \"input_ids\":inputs,\\n                            \"attention_mask\": att,\\n                            \"labels\":inputs\\n                        } \\n                            for inputs,att in zip(a[\\'input_ids\\'],a[\\'attention_mask\\'])\\n        ]\\n    def __len__(self):\\n        return len(self.dataset)\\n\\n    def __getitem__(self, idx):\\n        return self.dataset[idx]'"},"metadata":{}}]},{"cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        self.dialogue = tokenized_dataset['dialogue']\n        self.summary = tokenized_dataset['summary']\n        self.tokenized_dataset=tokenized_dataset\n    def __len__(self):\n        return len(self.tokenized_dataset)\n\n    def __getitem__(self, idx):\n        a=tokenizer(self.dialogue[idx] +f\"\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n\", return_tensors=\"pt\")\n        return {\n            \n                        \"input_ids\": a[\"input_ids\"].cuda(),\n            \"attention_mask\": a[\"attention_mask\"].cuda(),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:23.459443Z","iopub.execute_input":"2023-09-14T13:52:23.459832Z","iopub.status.idle":"2023-09-14T13:52:23.467169Z","shell.execute_reply.started":"2023-09-14T13:52:23.459800Z","shell.execute_reply":"2023-09-14T13:52:23.466150Z"},"editable":false,"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"dataset_train=SummarizationDataset(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:24.252281Z","iopub.execute_input":"2023-09-14T13:52:24.252674Z","iopub.status.idle":"2023-09-14T13:52:24.257297Z","shell.execute_reply.started":"2023-09-14T13:52:24.252643Z","shell.execute_reply":"2023-09-14T13:52:24.256288Z"},"editable":false,"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"print(data.iloc[23051,3])\nprint(data.iloc[23051,4])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:24.475864Z","iopub.execute_input":"2023-09-14T13:52:24.476870Z","iopub.status.idle":"2023-09-14T13:52:24.484557Z","shell.execute_reply.started":"2023-09-14T13:52:24.476831Z","shell.execute_reply":"2023-09-14T13:52:24.483633Z"},"editable":false,"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"رينجو: ماذا أحصل على سيليا من أجل عيد الميلاد؟\n لين: ooooo صعب\n رينجو: إنها أختك تعرفها بشكل أفضل\n winton: إنه gf الخاص بك أنت تعرفها أقرب\n رينجو: أنت غير مفيد للغاية\n لين: احصل عليها ايكيا sth\n ringo: sth لا يبدو prmising جدا\n رينجو: أنا ضائع جدا\n لين: ماذا عن القتال إلى إيطاليا؟احصل على قذيفة واحدة رخيصة تكون سعيدة على أي حال\n رينجو: يا سوبر ثكس كثيرا !!!\nلا يعرف رينجو ما يحصل على صديقته ، سيليا ، لعيد الميلاد.سيليا هي أخت وينتون.يقترح لين شيئًا من ايكيا أو رحلة رخيصة إلى إيطاليا.\n","output_type":"stream"}]},{"cell_type":"code","source":"w=a.merge_and_unload() ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:48:39.767637Z","iopub.execute_input":"2023-09-14T13:48:39.768094Z","iopub.status.idle":"2023-09-14T13:48:43.453923Z","shell.execute_reply.started":"2023-09-14T13:48:39.768059Z","shell.execute_reply":"2023-09-14T13:48:43.452874Z"},"editable":false,"trusted":true},"execution_count":136,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:205: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:04:39.439383Z","iopub.execute_input":"2023-09-14T14:04:39.440229Z","iopub.status.idle":"2023-09-14T14:04:39.453536Z","shell.execute_reply.started":"2023-09-14T14:04:39.440197Z","shell.execute_reply":"2023-09-14T14:04:39.452483Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":178,"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"BloomForCausalLM(\n  (transformer): BloomModel(\n    (word_embeddings): Embedding(250880, 2560)\n    (word_embeddings_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n    (h): ModuleList(\n      (0-29): 30 x BloomBlock(\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (self_attention): BloomAttention(\n          (query_key_value): Linear4bit(in_features=2560, out_features=7680, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (attention_dropout): Dropout(p=0.0, inplace=False)\n        )\n        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (mlp): BloomMLP(\n          (dense_h_to_4h): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (gelu_impl): BloomGelu()\n          (dense_4h_to_h): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n      )\n    )\n    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=250880, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:30:30.355669Z","iopub.execute_input":"2023-09-14T14:30:30.356112Z","iopub.status.idle":"2023-09-14T14:30:30.388384Z","shell.execute_reply.started":"2023-09-14T14:30:30.356078Z","shell.execute_reply":"2023-09-14T14:30:30.387476Z"},"editable":false,"trusted":true},"execution_count":182,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9e38a7270d4386a94e487bce2b8da3"}},"metadata":{}}]},{"cell_type":"code","source":"torch.save(w.state_dict(),\"bloom_weights.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:38:21.258142Z","iopub.execute_input":"2023-09-14T14:38:21.258733Z","iopub.status.idle":"2023-09-14T14:38:27.615725Z","shell.execute_reply.started":"2023-09-14T14:38:21.258700Z","shell.execute_reply":"2023-09-14T14:38:27.614421Z"},"editable":false,"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"w.push_to_hub(\"mohamedemam/Arabic-meeting-summarization\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:57:47.727140Z","iopub.execute_input":"2023-09-14T14:57:47.727574Z","iopub.status.idle":"2023-09-14T14:57:48.195322Z","shell.execute_reply.started":"2023-09-14T14:57:47.727543Z","shell.execute_reply":"2023-09-14T14:57:48.194047Z"},"editable":false,"trusted":true},"execution_count":189,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[189], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmohamedemam/Arabic-meeting-summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:893\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(work_dir)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Save all files.\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_modified_files(\n\u001b[1;32m    896\u001b[0m     work_dir,\n\u001b[1;32m    897\u001b[0m     repo_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    903\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1868\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1862\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` to a 8-bit converted model you may likely encounter unexepected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m behaviors. If you want to save 8-bit models, make sure to have `bitsandbytes>0.37.2` installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1865\u001b[0m     )\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1870\u001b[0m     )\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1873\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1875\u001b[0m     )\n","\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"],"ename":"NotImplementedError","evalue":"You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported","output_type":"error"}]},{"cell_type":"code","source":"huggingface_hub.(\"mohamedemam/Arabic-meeting-summarization\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:34:58.232187Z","iopub.execute_input":"2023-09-14T14:34:58.232570Z","iopub.status.idle":"2023-09-14T14:34:58.439671Z","shell.execute_reply.started":"2023-09-14T14:34:58.232540Z","shell.execute_reply":"2023-09-14T14:34:58.437810Z"},"editable":false,"trusted":true},"execution_count":185,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmohamedemam/Arabic-meeting-summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:893\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(work_dir)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Save all files.\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_modified_files(\n\u001b[1;32m    896\u001b[0m     work_dir,\n\u001b[1;32m    897\u001b[0m     repo_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    903\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1868\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1862\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` to a 8-bit converted model you may likely encounter unexepected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m behaviors. If you want to save 8-bit models, make sure to have `bitsandbytes>0.37.2` installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1865\u001b[0m     )\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1870\u001b[0m     )\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1873\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1875\u001b[0m     )\n","\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"],"ename":"NotImplementedError","evalue":"You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported","output_type":"error"}]},{"cell_type":"code","source":"output_tokens = a.generate(**dataset_test[153], max_new_tokens=50,do_sample=True,num_return_sequences=4 , num_beams=6 ,temperature=.8, top_p=0.9\n                          )\nfor i in tokenizer.batch_decode(output_tokens,skip_special_tokens=True):\n            print(i)\n            print(\"end\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:26:04.152339Z","iopub.execute_input":"2023-09-14T14:26:04.153432Z","iopub.status.idle":"2023-09-14T14:26:08.652879Z","shell.execute_reply.started":"2023-09-14T14:26:04.153384Z","shell.execute_reply":"2023-09-14T14:26:08.651913Z"},"editable":false,"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"الشخص 1: يا لها من بلوزة جذابة ، تبدو جميلًا جدًا في هذا الفستان الأزرق!\n  الشخص 2: حقا؟شكرًا لك.اشتريتها في شارع سبرينغ أمس.\n  الشخص 1: إنه لطيف للغاية.يسير على ما يرام مع تنورتك.\n  الشخص 2: شكرا لك.من الجيد جدًا منك أن تقول ذلك.\n  الشخص 1: ليس على الإطلاق.هذا الفستان يظهر بالتأكيد ذوقك الجيد.\n  الشخص 2: هذا مجاملة قادمة منك.\n\nSummarize the previous text in three sentences in arabic:\n\nيطلب شخص من شخص آخر شراء فستان.\nend\nالشخص 1: يا لها من بلوزة جذابة ، تبدو جميلًا جدًا في هذا الفستان الأزرق!\n  الشخص 2: حقا؟شكرًا لك.اشتريتها في شارع سبرينغ أمس.\n  الشخص 1: إنه لطيف للغاية.يسير على ما يرام مع تنورتك.\n  الشخص 2: شكرا لك.من الجيد جدًا منك أن تقول ذلك.\n  الشخص 1: ليس على الإطلاق.هذا الفستان يظهر بالتأكيد ذوقك الجيد.\n  الشخص 2: هذا مجاملة قادمة منك.\n\nSummarize the previous text in three sentences in arabic:\n\nيطلب شخص من شخص آخر شراء فستان له.\nend\nالشخص 1: يا لها من بلوزة جذابة ، تبدو جميلًا جدًا في هذا الفستان الأزرق!\n  الشخص 2: حقا؟شكرًا لك.اشتريتها في شارع سبرينغ أمس.\n  الشخص 1: إنه لطيف للغاية.يسير على ما يرام مع تنورتك.\n  الشخص 2: شكرا لك.من الجيد جدًا منك أن تقول ذلك.\n  الشخص 1: ليس على الإطلاق.هذا الفستان يظهر بالتأكيد ذوقك الجيد.\n  الشخص 2: هذا مجاملة قادمة منك.\n\nSummarize the previous text in three sentences in arabic:\n\nيطلب شخص من شخص آخر أن يثني عليه.\nend\nالشخص 1: يا لها من بلوزة جذابة ، تبدو جميلًا جدًا في هذا الفستان الأزرق!\n  الشخص 2: حقا؟شكرًا لك.اشتريتها في شارع سبرينغ أمس.\n  الشخص 1: إنه لطيف للغاية.يسير على ما يرام مع تنورتك.\n  الشخص 2: شكرا لك.من الجيد جدًا منك أن تقول ذلك.\n  الشخص 1: ليس على الإطلاق.هذا الفستان يظهر بالتأكيد ذوقك الجيد.\n  الشخص 2: هذا مجاملة قادمة منك.\n\nSummarize the previous text in three sentences in arabic:\n\nيطلب شخص من شخص آخر شراء فستان زهري.\nend\n","output_type":"stream"}]},{"cell_type":"code","source":"output_tokens = a.generate(**dataset_train[23007], max_new_tokens=50,top_p=.4,do_sample=True,num_return_sequences=4 , num_beams=4,temperature =1.5)\nfor i in tokenizer.batch_decode(output_tokens,skip_special_tokens=True):\n            print(i)\n            print(\"end\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:43.257219Z","iopub.execute_input":"2023-09-14T13:52:43.257629Z","iopub.status.idle":"2023-09-14T13:52:43.341232Z","shell.execute_reply.started":"2023-09-14T13:52:43.257595Z","shell.execute_reply":"2023-09-14T13:52:43.340014Z"},"editable":false,"trusted":true},"execution_count":157,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mdataset_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m23007\u001b[39;49m\u001b[43m]\u001b[49m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.4\u001b[39m,do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m , num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,temperature \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(output_tokens,skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;28mprint\u001b[39m(i)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:17:53.345615Z","iopub.execute_input":"2023-09-14T13:17:53.346019Z","iopub.status.idle":"2023-09-14T13:17:53.350644Z","shell.execute_reply.started":"2023-09-14T13:17:53.345968Z","shell.execute_reply":"2023-09-14T13:17:53.349673Z"},"editable":false,"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import  random_split","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:17:53.592554Z","iopub.execute_input":"2023-09-14T13:17:53.593163Z","iopub.status.idle":"2023-09-14T13:17:53.597983Z","shell.execute_reply.started":"2023-09-14T13:17:53.593128Z","shell.execute_reply":"2023-09-14T13:17:53.597019Z"},"editable":false,"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"dataset_train,dataset_valid,dataset_test=random_split(dataset_train,[.85,.075,.075])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:34.993282Z","iopub.execute_input":"2023-09-14T13:52:34.993649Z","iopub.status.idle":"2023-09-14T13:52:35.000464Z","shell.execute_reply.started":"2023-09-14T13:52:34.993620Z","shell.execute_reply":"2023-09-14T13:52:34.999359Z"},"editable":false,"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.532213Z","iopub.execute_input":"2023-09-13T18:37:26.533162Z","iopub.status.idle":"2023-09-13T18:37:26.539279Z","shell.execute_reply.started":"2023-09-13T18:37:26.533129Z","shell.execute_reply":"2023-09-13T18:37:26.538380Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.enable_input_require_grads()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.540585Z","iopub.execute_input":"2023-09-13T18:37:26.541134Z","iopub.status.idle":"2023-09-13T18:37:26.553674Z","shell.execute_reply.started":"2023-09-13T18:37:26.541102Z","shell.execute_reply":"2023-09-13T18:37:26.552779Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.555043Z","iopub.execute_input":"2023-09-13T18:37:26.555431Z","iopub.status.idle":"2023-09-13T18:37:30.562194Z","shell.execute_reply.started":"2023-09-13T18:37:26.555401Z","shell.execute_reply":"2023-09-13T18:37:30.561265Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = TrainingArguments(\n    output_dir=\"./results_modified\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=26,\n    save_steps=200,\n    learning_rate=2e-5,\n            fp16=True\n,\n    weight_decay=0.001,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"constant\",\n)\ntrainer = Trainer(\n    model=model,\n    args=train_params,\n    train_dataset=dataset_train,\n    eval_dataset=dataset_valid\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:30.563544Z","iopub.execute_input":"2023-09-13T18:37:30.564435Z","iopub.status.idle":"2023-09-13T18:37:32.422972Z","shell.execute_reply.started":"2023-09-13T18:37:30.564394Z","shell.execute_reply":"2023-09-13T18:37:32.421990Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load(\"/kaggle/working/bloom_weights.pth\")","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:32.424182Z","iopub.execute_input":"2023-09-13T18:37:32.424905Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'bloomz.pt')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}