{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install gradio peft","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:46:52.645666Z","iopub.execute_input":"2023-09-14T15:46:52.646361Z","iopub.status.idle":"2023-09-14T15:47:13.249500Z","shell.execute_reply.started":"2023-09-14T15:46:52.646311Z","shell.execute_reply":"2023-09-14T15:47:13.248426Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-3.44.2-py3-none-any.whl (20.2 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.1.1)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.98.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.5.0 (from gradio)\n  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx (from gradio)\n  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.16.4)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.12.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.2)\nRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.23.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.0.2)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.10.9)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart (from gradio)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0)\nRequirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.31.0)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.6.3)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.22.0)\nRequirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (11.0.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==0.5.0->gradio) (2023.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.33.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.3)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.4)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.0->gradio) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.27.0)\nCollecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio)\n  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio) (3.7.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.19.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio) (1.1.1)\nBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=d630905bb9070b43d30bb5f82d81bcc6794b4ae6570f55cf95c7feeaf984d471\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, semantic-version, python-multipart, httpcore, httpx, peft, gradio-client, gradio\nSuccessfully installed ffmpy-0.3.1 gradio-3.44.2 gradio-client-0.5.0 httpcore-0.18.0 httpx-0.25.0 peft-0.5.0 python-multipart-0.0.6 semantic-version-2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:01:12.068425Z","iopub.execute_input":"2023-09-14T16:01:12.069091Z","iopub.status.idle":"2023-09-14T16:01:17.385170Z","shell.execute_reply.started":"2023-09-14T16:01:12.069051Z","shell.execute_reply":"2023-09-14T16:01:17.384170Z"},"editable":false,"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:02:39.523415Z","iopub.execute_input":"2023-09-14T16:02:39.523849Z","iopub.status.idle":"2023-09-14T16:02:39.533470Z","shell.execute_reply.started":"2023-09-14T16:02:39.523815Z","shell.execute_reply":"2023-09-14T16:02:39.532453Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"torch.set_default_device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:07:24.944977Z","iopub.execute_input":"2023-09-14T16:07:24.945422Z","iopub.status.idle":"2023-09-14T16:07:24.952318Z","shell.execute_reply.started":"2023-09-14T16:07:24.945387Z","shell.execute_reply":"2023-09-14T16:07:24.950987Z"},"editable":false,"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gradio as gr\nfrom transformers import AutoTokenizer\nimport re\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig\nimport torch\n\nconfig = PeftConfig.from_pretrained(\"mohamedemam/Arabic-meeting-summarization\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-3b\",quantization_config=bnb_config)\nmodel = PeftModel.from_pretrained(model, \"mohamedemam/Arabic-meeting-summarization\")\n# Load the tokenizer and model\nmodel_name =\"bigscience/bloomz-3b\"\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-3b\")\nmodel.eval()\n\n# Function to generate questions and answers with configurable parameters\ndef generate_qa(context, temperature, top_p,num_seq,l_p, num_b):\n    input_text = context\n    input_ids = tokenizer(text=input_text, return_tensors='pt')\n    \n    # Generate with configurable parameters\n    output = model.generate(\n        **input_ids,\n        temperature=temperature,\n        top_p=top_p,\n        num_return_sequences=num_seq,\n   \n        max_new_tokens=60,\n        num_beams=num_b,\n        length_penalty=l_p,    \n        do_sample=True,\n        \n    )\n    #\n    generated_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n\n    formatted_output = \"\\n\\n\".join(set(generated_text))\n    return formatted_output\niface = gr.Interface(\n    fn=generate_qa,\n    inputs=[\n        gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n        gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),     \n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"), \n        gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n     ,\n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n\n\n    ],\n    outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n    title=\"Question Generation and Answering\",\n    description=\"Select an example context, choose a recommended word, adjust temperature and top-p. The model will generate questions and answers.\",\n)\n# Launch the interface\niface.launch()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:32:37.706423Z","iopub.execute_input":"2023-09-14T16:32:37.707481Z","iopub.status.idle":"2023-09-14T16:32:41.845140Z","shell.execute_reply.started":"2023-09-14T16:32:37.707429Z","shell.execute_reply":"2023-09-14T16:32:41.843713Z"},"jupyter":{"source_hidden":true},"editable":false,"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"    a = tokenizer(text=\"as\", return_tensors='pt')\n    \n    # Generate with configurable parameters\n    output = model.generate(input_ids= a['input_ids'].cuda(),\n        temperature=1.2,\n        top_p=.3,\n        num_return_sequences=2,\n        max_new_tokens=60,\n        num_beams=3,\n        length_penalty=1,    \n        do_sample=True,\n        \n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:15:43.922280Z","iopub.execute_input":"2023-09-14T16:15:43.922731Z","iopub.status.idle":"2023-09-14T16:15:50.204650Z","shell.execute_reply.started":"2023-09-14T16:15:43.922700Z","shell.execute_reply":"2023-09-14T16:15:50.203572Z"},"editable":false,"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"w=\"\"\ndef generate_qa(context, temperature, top_p,num_seq,l_p, num_b):\n    input_text = f\"{context}\"+f\"\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n\"\n    input_ids = tokenizer(text=input_text, return_tensors='pt')\n    global w\n    w=input_text\n    # Generate with configurable parameters\n    output = model.generate(\n        input_ids=input_ids['input_ids'].cuda(),\n        temperature=temperature,\n        top_p=top_p,\n        num_return_sequences=num_seq,\n   \n        max_new_tokens=60,\n        num_beams=num_b,\n        length_penalty=l_p,    \n        do_sample=True,\n        \n    )\n    \n    #\n    generated_text = tokenizer.batch_decode(output, skip_special_tokens=True)\n\n    formatted_output = \"\\n\\n\".join(set(generated_text))\n    return formatted_output","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:37:36.270448Z","iopub.execute_input":"2023-09-14T16:37:36.270870Z","iopub.status.idle":"2023-09-14T16:37:36.279238Z","shell.execute_reply.started":"2023-09-14T16:37:36.270836Z","shell.execute_reply":"2023-09-14T16:37:36.278220Z"},"editable":false,"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\niface = gr.Interface(\n    fn=generate_qa,\n    inputs=[\n        \"text\",\n        gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n        gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),     \n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"), \n        gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n     ,\n        gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n\n\n    ],\n    outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n    title=\"Question Generation and Answering\",\n    description=\"Select an example context, choose a recommended word, adjust temperature and top-p. The model will generate questions and answers.\",\n)\n# Launch the interface\niface.launch()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:37:36.972293Z","iopub.execute_input":"2023-09-14T16:37:36.972691Z","iopub.status.idle":"2023-09-14T16:37:45.505645Z","shell.execute_reply.started":"2023-09-14T16:37:36.972659Z","shell.execute_reply":"2023-09-14T16:37:45.504668Z"},"editable":false,"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_94/1303577419.py:5: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n/tmp/ipykernel_94/1303577419.py:5: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.0, maximum=5, default=2.1, step=0.01, label=\"Temperature\"),\n/tmp/ipykernel_94/1303577419.py:6: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),\n/tmp/ipykernel_94/1303577419.py:6: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.0, maximum=1, default=0.5, step=0.01, label=\"Top-p\"),\n/tmp/ipykernel_94/1303577419.py:7: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"),\n/tmp/ipykernel_94/1303577419.py:7: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of sequance\"),\n/tmp/ipykernel_94/1303577419.py:8: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n/tmp/ipykernel_94/1303577419.py:8: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=0.01, maximum=5, default=3, step=.01, label=\"l_p\")\n/tmp/ipykernel_94/1303577419.py:10: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n/tmp/ipykernel_94/1303577419.py:10: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n  gr.inputs.Slider(minimum=1, maximum=20, default=3, step=1, label=\"num of beams\"),\n/tmp/ipykernel_94/1303577419.py:14: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  outputs=gr.outputs.Textbox(label=\"Generated Output\"),\n","output_type":"stream"},{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7869\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\nRunning on public URL: https://b2c8cfc5855ddb5f9b.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://b2c8cfc5855ddb5f9b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}]},{"cell_type":"code","source":"w","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:38:00.463359Z","iopub.execute_input":"2023-09-14T16:38:00.463800Z","iopub.status.idle":"2023-09-14T16:38:00.471235Z","shell.execute_reply.started":"2023-09-14T16:38:00.463768Z","shell.execute_reply":"2023-09-14T16:38:00.470208Z"},"editable":false,"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'Ù…Ø±Ø­Ø¨Ù‹Ø§ØŒ Ø£Ù†Ø§ Ø¯ÙŠÙÙŠØ¯ ÙˆÙ…Ù† Ø§Ù„Ù…ÙØªØ±Ø¶ Ø£Ù† Ø£ÙƒÙˆÙ† Ù…ØµÙ…Ù…Ù‹Ø§ ØµÙ†Ø§Ø¹ÙŠÙ‹Ø§. Ø£Ù…ØŒ Ù„Ù‚Ø¯ Ø­ØµÙ„Øª Ù„Ù„ØªÙˆ Ø¹Ù„Ù‰ Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø­ÙˆÙ„ Ù…Ø§Ù‡ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ¹. ØªØµÙ…ÙŠÙ… Ø¬Ù‡Ø§Ø² Ø§Ù„ØªØ­ÙƒÙ… Ø¹Ù† Ø¨Ø¹Ø¯. Ù‡Ø°Ø§ ÙƒÙ„ Ù…Ø§ ÙÙŠ Ø§Ù„Ø£Ù…Ø±ØŒ ÙˆÙ„Ù… Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø±. Ù‡Ù„ Ø­ØµÙ„Øª Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ø´ÙŠØ¡ØŸ Ø±Ø§Ø¦Ø¹. Ù‡Ù†Ø§Ùƒ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø¹ØªØ§Ø¯. ØªÙ…Ø§Ù…. Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„Ø±Ø³Ù…. Ø£Ù…. Ù†Ø¹Ù…. Ø­Ø³Ù†Ù‹Ø§ Ø¹Ù„Ù‰ Ø£ÙŠØ© Ø­Ø§Ù„ØŒ Ù„Ø§ Ø£Ø¹Ø±ÙØŒ Ø¥Ù†Ù‡ Ø£ÙˆÙ„ Ø­ÙŠÙˆØ§Ù† ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙÙŠÙ‡ Ù…Ù† Ø£Ø¹Ù„Ù‰ Ø±Ø£Ø³ÙŠ. Ø£Ù…. Ù†Ø¹Ù…. Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù‡Ùˆ Ø£Ù†Ù†ÙŠ Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ© ØªØ¬Ø§Ù‡ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª. Ø­Ø³Ø§Ø³ÙŠØ© Ù…Ù† ÙØ±Ø§Ø¡ Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§ØªØŒ Ù„Ø°Ù„Ùƒ ÙƒØ§Ù†Øª Ø§Ù„Ø£Ø³Ù…Ø§Ùƒ Ø®ÙŠØ§Ø±Ù‹Ø§ Ø·Ø¨ÙŠØ¹ÙŠÙ‹Ø§. Ø£Ù…ØŒ Ù†Ø¹Ù…ØŒ ÙˆØ£Ù†Ø§ Ø£Ø­Ø¨ Ø§Ù„Ø­ÙŠØªØ§Ù† Ù†ÙˆØ¹Ù‹Ø§ Ù…Ø§. ÙŠØ£ØªÙˆÙ† ÙˆÙŠØ°Ù‡Ø¨ÙˆÙ† ÙˆÙŠØ£ÙƒÙ„ÙˆÙ† ÙƒÙ„ Ø´ÙŠØ¡ ÙÙŠ Ø§Ù„Ø£ÙÙ‚. ÙˆÙ‡ÙŠ ØºÙŠØ± Ø¶Ø§Ø±Ø© ØªÙ…Ø§Ù…Ù‹Ø§ ÙˆØ®ÙÙŠÙØ© ÙˆÙ…Ø«ÙŠØ±Ø© Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…. Ø§Ù„Ø°ÙŠÙ„ ÙƒØ¨ÙŠØ± Ø¨Ø¹Ø¶ Ø§Ù„Ø´ÙŠØ¡ØŒ Ø¹Ù„Ù‰ Ù…Ø§ Ø£Ø¹ØªÙ‚Ø¯. Ø¥Ù†Ù‡ ÙƒÙ„Ø¨ Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ø´Ø§Ø¡ Ø¥Ø°Ù†. Ù‡Ù…Ù…. Ø±Ø¨Ù…Ø§ ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ù…Ù†Ø·Ù‚ÙŠÙ‹Ø§ Ù…Ù† ÙˆØ¬Ù‡Ø© Ù†Ø¸Ø± Ø§Ù„ØªØµÙ…ÙŠÙ…ØŒ Ù„Ø£Ù†Ù‡ Ù„Ø¯ÙŠÙƒ Ø£Ø­Ø±Ù Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ù‹Ø§ Ù…Ø«Ù„ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠØ©ØŒ ÙØ£Ù†Øª Ø¨Ø­Ø§Ø¬Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø±. Ù„Ø°Ù„ÙƒØŒ Ø±Ø¨Ù…Ø§. Ù‡Ù…Ù…. Ù†Ø¹Ù…. ÙˆØªØ³ØªÙ…Ø± ÙÙŠ Ø®Ø³Ø§Ø±ØªÙ‡Ù…. Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„ÙŠÙ‡Ù… Ø£Ù…Ø± Ù…Ø¤Ù„Ù… Ø­Ù‚Ù‹Ø§ØŒ ÙƒÙ…Ø§ ØªØ¹Ù„Ù…ÙˆÙ†. Ø£Ø¹Ù†ÙŠ Ø£Ù†Ù‡Ø§ Ø¹Ø§Ø¯Ø© Ù…Ø§ ØªÙƒÙˆÙ† ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ØŒ Ø£Ùˆ Ø¹Ù†Ø¯Ù…Ø§ ØªØ±ÙŠØ¯Ù‡Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ØŒ ØªÙ†Ø²Ù„Ù‚ Ø®Ù„Ù Ø§Ù„Ø£Ø±ÙŠÙƒØ© Ø£Ùˆ ÙŠØªÙ… Ø±ÙƒÙ„Ù‡Ø§ ØªØ­Øª Ø§Ù„Ø·Ø§ÙˆÙ„Ø©. Ø£Ù†Øª ØªØ¹Ø±Ù. Ù†Ø¹Ù…. Ù…Ù…-Ù‡Ù…Ù…Ù…. Ø£Ø¹ØªÙ‚Ø¯ Ø£Ù† Ø£Ø­Ø¯ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø³ÙŠÙƒÙˆÙ† ØªÙƒÙ„ÙØ© Ø§Ù„Ø¥Ù†ØªØ§Ø¬. Ù†Ø¸Ø±Ù‹Ø§ Ù„ÙˆØ¬ÙˆØ¯ Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù‡Ù†Ø§ÙƒØŒ Ù„Ø°Ø§ ÙŠØ¹ØªÙ…Ø¯ Ø§Ù„Ø£Ù…Ø± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ø°ÙŠ ÙŠÙ…ÙƒÙ†Ùƒ Ø­Ø´Ø±Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¹Ø±. Ø£Ù…. Ø£Ø¹ØªÙ‚Ø¯ Ø£Ù† Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ. Ø±Ø§Ø¦Ø¹.\\n\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-14T11:44:47.646794Z","iopub.execute_input":"2023-09-14T11:44:47.647077Z","iopub.status.idle":"2023-09-14T11:44:47.994751Z","shell.execute_reply.started":"2023-09-14T11:44:47.647044Z","shell.execute_reply":"2023-09-14T11:44:47.993835Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:59:01.666941Z","iopub.execute_input":"2023-09-14T15:59:01.667352Z","iopub.status.idle":"2023-09-14T15:59:18.833012Z","shell.execute_reply.started":"2023-09-14T15:59:01.667317Z","shell.execute_reply":"2023-09-14T15:59:18.831688Z"},"editable":false,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.41.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/transformers.git ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T15:59:18.836910Z","iopub.execute_input":"2023-09-14T15:59:18.837253Z","iopub.status.idle":"2023-09-14T16:00:05.598966Z","shell.execute_reply.started":"2023-09-14T15:59:18.837218Z","shell.execute_reply":"2023-09-14T16:00:05.597767Z"},"editable":false,"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-18b1g5zp\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-18b1g5zp\n  Resolved https://github.com/huggingface/transformers.git to commit 44a0490d3c46e62134b3fc1f0609cbdf83e571da\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.34.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (2023.7.22)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7662134 sha256=36a9b38770edeb9d3ceebf6f3a28bec5422137799c511d9407f56c77428f20ac\n  Stored in directory: /tmp/pip-ephem-wheel-cache-h_telic9/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\nSuccessfully installed transformers-4.34.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/peft.git\n!pip install  -U git+https://github.com/huggingface/accelerate.git\n!pip install  datasets","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:00:05.600636Z","iopub.execute_input":"2023-09-14T16:00:05.601038Z","iopub.status.idle":"2023-09-14T16:01:12.065760Z","shell.execute_reply.started":"2023-09-14T16:00:05.601000Z","shell.execute_reply":"2023-09-14T16:01:12.064580Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/peft.git\n  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-p7n3nssw\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-p7n3nssw\n  Resolved https://github.com/huggingface/peft.git to commit 93d0c03d5ba6b2a6b16b7ca887e740a67bc680f3\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.34.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (0.22.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (0.3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.6.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (0.16.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->peft==0.6.0.dev0) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.6.0.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.6.0.dev0) (1.3.0)\nBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=107812 sha256=d83f766d5ce6ca0c04f8ee7f90fd6585fddd40d4e1adb69ba2675e63c389cb43\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rkpsim6r/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\nSuccessfully built peft\nInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.5.0\n    Uninstalling peft-0.5.0:\n      Successfully uninstalled peft-0.5.0\nSuccessfully installed peft-0.6.0.dev0\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-hq6ehyc7\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-hq6ehyc7\n  Resolved https://github.com/huggingface/accelerate.git to commit bbcdbbaffc2f0d5619f0e16c90a4c8b7e088c27f\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.23.0.dev0) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.23.0.dev0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.23.0.dev0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.23.0.dev0) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.23.0.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.23.0.dev0) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.23.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.23.0.dev0-py3-none-any.whl size=258131 sha256=00f1a14f4e3da8ef08ba251815f79d95217a83dadbc9fa5ddeb4786f6635c850\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dt8dhfuz/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed accelerate-0.23.0.dev0\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:44:54.819074Z","iopub.execute_input":"2023-09-14T16:44:54.819792Z","iopub.status.idle":"2023-09-14T16:44:54.825201Z","shell.execute_reply.started":"2023-09-14T16:44:54.819757Z","shell.execute_reply":"2023-09-14T16:44:54.824209Z"},"editable":false,"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:44:55.076047Z","iopub.execute_input":"2023-09-14T16:44:55.076977Z","iopub.status.idle":"2023-09-14T16:44:55.926983Z","shell.execute_reply.started":"2023-09-14T16:44:55.076946Z","shell.execute_reply":"2023-09-14T16:44:55.925900Z"},"editable":false,"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data.iloc[1221,3]","metadata":{"execution":{"iopub.status.busy":"2023-09-14T16:47:54.897568Z","iopub.execute_input":"2023-09-14T16:47:54.897949Z","iopub.status.idle":"2023-09-14T16:47:54.904605Z","shell.execute_reply.started":"2023-09-14T16:47:54.897919Z","shell.execute_reply":"2023-09-14T16:47:54.903587Z"},"editable":false,"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"'Ø¥Ù…ÙŠÙ„ÙŠ: ğŸ‘»\\n Ø¥Ù…ÙŠÙ„ÙŠ: Ù…Ø±Ø­Ø¨Ø§.Ù‡Ù„ ØªØ´Ø¹Ø± Ø¨Ø§Ù„Ø±ØºØ¨Ø© ÙÙŠ ØªÙ†Ø§ÙˆÙ„ Ø§Ù„Ø¹Ø´Ø§Ø¡ ÙÙŠ Ù†Ø§Ù†Ø¯Ùˆ Ø§Ù„Ù„ÙŠÙ„Ø©ØŸ\\n Ø¥Ù…ÙŠÙ„ÙŠ: ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø­Ø¬Ø² Ø·Ø§ÙˆÙ„Ø©\\n Ø¨Ø§ÙƒÙˆ: Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ ØŒ Ø§Ø°Ù‡Ø¨ Ø¥Ù„ÙŠÙ‡Ø§\\n Ù…Ø§ÙŠÙƒÙ„: Ù†Ø¹Ù… Ù…Ù† ÙØ¶Ù„Ùƒ.Ø£Ù†Ø§ Ø¹Ù„Ù‰ ÙˆØ´Ùƒ Ø£Ø®Ø° Ø§Ù„Ø£Ù†Ø¨ÙˆØ¨ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ø²Ù„ Ø§Ù„Ø¢Ù†\\n Ù…Ø§ÙŠÙƒÙ„: Ø£Ø±ØºØ¨ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ­Ù…Ø§Ù… Ù‚Ø¨Ù„ Ø§Ù„Ø®Ø±ÙˆØ¬ ØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø­Ø¬Ø² Ø§Ù„Ø¬Ø¯ÙˆÙ„ ØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ ØŒ 8 Ù…Ø³Ø§Ø¡Ù‹ØŸ\\n Ø¥Ù…ÙŠÙ„ÙŠ: Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ ØŒ Ù„Ø§ Ù…Ø´ÙƒÙ„Ø©\\n Ù…Ø§ÙŠÙƒÙ„: Ø£Ø±Ø§Ùƒ Ù‚Ø±ÙŠØ¨Ù‹Ø§ Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø§Ù„\\n Ø¥Ù…ÙŠÙ„ÙŠ: Ø¨Ø§Ø±Ø¯\\n Ø¨Ø§ÙƒÙˆ: ğŸ‘Œ'"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-3b\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-3b\",quantization_config=nf4_config,)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:47:19.607055Z","iopub.execute_input":"2023-09-14T11:47:19.607571Z","iopub.status.idle":"2023-09-14T11:48:17.397613Z","shell.execute_reply.started":"2023-09-14T11:47:19.607537Z","shell.execute_reply":"2023-09-14T11:48:17.396620Z"},"editable":false,"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/199 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500f7bb1c3c343d5b54e9baf9982ab77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f885e8b0286a4806883956681aabd6b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a953611c017c400ea9fdb53b45d16e6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a2201e32db143b193a717352150d6c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/6.01G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1147a4a4aaae40a98f974ceb2890e155"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install peft","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:48:17.398966Z","iopub.execute_input":"2023-09-14T11:48:17.399581Z","iopub.status.idle":"2023-09-14T11:48:30.099403Z","shell.execute_reply.started":"2023-09-14T11:48:17.399546Z","shell.execute_reply":"2023-09-14T11:48:30.098071Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.6.0.dev0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.34.0.dev0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.0.dev0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.3)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft) (2023.9.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=4, \n    lora_alpha=16, \n            target_modules=[\"query_key_value\"],\n\n    lora_dropout=0.05, \n    bias=\"none\", \n    \n    task_type=\"CAUSAL_LM\"\n)\n#model = get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:49:25.663516Z","iopub.execute_input":"2023-09-14T11:49:25.663950Z","iopub.status.idle":"2023-09-14T11:49:25.710886Z","shell.execute_reply.started":"2023-09-14T11:49:25.663915Z","shell.execute_reply":"2023-09-14T11:49:25.709855Z"},"editable":false,"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from peft import AutoPeftModel,PeftModel","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:52:36.837825Z","iopub.execute_input":"2023-09-14T11:52:36.838230Z","iopub.status.idle":"2023-09-14T11:52:36.843083Z","shell.execute_reply.started":"2023-09-14T11:52:36.838198Z","shell.execute_reply":"2023-09-14T11:52:36.842158Z"},"editable":false,"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"a=PeftModel.from_pretrained(model,\"/kaggle/input/blooma/results_modified/checkpoint-800\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:04.463466Z","iopub.execute_input":"2023-09-14T11:53:04.463854Z","iopub.status.idle":"2023-09-14T11:53:09.809405Z","shell.execute_reply.started":"2023-09-14T11:53:04.463823Z","shell.execute_reply":"2023-09-14T11:53:09.808439Z"},"editable":false,"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:09.811266Z","iopub.execute_input":"2023-09-14T11:53:09.811601Z","iopub.status.idle":"2023-09-14T11:53:10.606730Z","shell.execute_reply.started":"2023-09-14T11:53:09.811570Z","shell.execute_reply":"2023-09-14T11:53:10.605760Z"},"editable":false,"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:10.608087Z","iopub.execute_input":"2023-09-14T11:53:10.608439Z","iopub.status.idle":"2023-09-14T11:53:10.613659Z","shell.execute_reply.started":"2023-09-14T11:53:10.608407Z","shell.execute_reply":"2023-09-14T11:53:10.612744Z"},"editable":false,"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\"\"\"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        a = tokenizer( (data['dialogue']+data['summary']).tolist(), truncation=True, padding='max_length', return_tensors=\"pt\", max_length=512)\n        self.dataset=  [\n            {\n            \n                            \"input_ids\":inputs,\n                            \"attention_mask\": att,\n                            \"labels\":inputs\n                        } \n                            for inputs,att in zip(a['input_ids'],a['attention_mask'])\n        ]\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return self.dataset[idx]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-14T11:53:10.615979Z","iopub.execute_input":"2023-09-14T11:53:10.617020Z","iopub.status.idle":"2023-09-14T11:53:10.630924Z","shell.execute_reply.started":"2023-09-14T11:53:10.616969Z","shell.execute_reply":"2023-09-14T11:53:10.629948Z"},"editable":false,"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"'class SummarizationDataset(Dataset):\\n    def __init__(self, tokenized_dataset):\\n        a = tokenizer( (data[\\'dialogue\\']+data[\\'summary\\']).tolist(), truncation=True, padding=\\'max_length\\', return_tensors=\"pt\", max_length=512)\\n        self.dataset=  [\\n            {\\n            \\n                            \"input_ids\":inputs,\\n                            \"attention_mask\": att,\\n                            \"labels\":inputs\\n                        } \\n                            for inputs,att in zip(a[\\'input_ids\\'],a[\\'attention_mask\\'])\\n        ]\\n    def __len__(self):\\n        return len(self.dataset)\\n\\n    def __getitem__(self, idx):\\n        return self.dataset[idx]'"},"metadata":{}}]},{"cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        self.dialogue = tokenized_dataset['dialogue']\n        self.summary = tokenized_dataset['summary']\n        self.tokenized_dataset=tokenized_dataset\n    def __len__(self):\n        return len(self.tokenized_dataset)\n\n    def __getitem__(self, idx):\n        a=tokenizer(self.dialogue[idx] +f\"\\n\\nSummarize the previous text in three sentences in arabic:\\n\\n\", return_tensors=\"pt\")\n        return {\n            \n                        \"input_ids\": a[\"input_ids\"].cuda(),\n            \"attention_mask\": a[\"attention_mask\"].cuda(),\n        }","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:23.459443Z","iopub.execute_input":"2023-09-14T13:52:23.459832Z","iopub.status.idle":"2023-09-14T13:52:23.467169Z","shell.execute_reply.started":"2023-09-14T13:52:23.459800Z","shell.execute_reply":"2023-09-14T13:52:23.466150Z"},"editable":false,"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"dataset_train=SummarizationDataset(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:24.252281Z","iopub.execute_input":"2023-09-14T13:52:24.252674Z","iopub.status.idle":"2023-09-14T13:52:24.257297Z","shell.execute_reply.started":"2023-09-14T13:52:24.252643Z","shell.execute_reply":"2023-09-14T13:52:24.256288Z"},"editable":false,"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"print(data.iloc[23051,3])\nprint(data.iloc[23051,4])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:24.475864Z","iopub.execute_input":"2023-09-14T13:52:24.476870Z","iopub.status.idle":"2023-09-14T13:52:24.484557Z","shell.execute_reply.started":"2023-09-14T13:52:24.476831Z","shell.execute_reply":"2023-09-14T13:52:24.483633Z"},"editable":false,"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"Ø±ÙŠÙ†Ø¬Ùˆ: Ù…Ø§Ø°Ø§ Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø³ÙŠÙ„ÙŠØ§ Ù…Ù† Ø£Ø¬Ù„ Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ØŸ\n Ù„ÙŠÙ†: ooooo ØµØ¹Ø¨\n Ø±ÙŠÙ†Ø¬Ùˆ: Ø¥Ù†Ù‡Ø§ Ø£Ø®ØªÙƒ ØªØ¹Ø±ÙÙ‡Ø§ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„\n winton: Ø¥Ù†Ù‡ gf Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø£Ù†Øª ØªØ¹Ø±ÙÙ‡Ø§ Ø£Ù‚Ø±Ø¨\n Ø±ÙŠÙ†Ø¬Ùˆ: Ø£Ù†Øª ØºÙŠØ± Ù…ÙÙŠØ¯ Ù„Ù„ØºØ§ÙŠØ©\n Ù„ÙŠÙ†: Ø§Ø­ØµÙ„ Ø¹Ù„ÙŠÙ‡Ø§ Ø§ÙŠÙƒÙŠØ§ sth\n ringo: sth Ù„Ø§ ÙŠØ¨Ø¯Ùˆ prmising Ø¬Ø¯Ø§\n Ø±ÙŠÙ†Ø¬Ùˆ: Ø£Ù†Ø§ Ø¶Ø§Ø¦Ø¹ Ø¬Ø¯Ø§\n Ù„ÙŠÙ†: Ù…Ø§Ø°Ø§ Ø¹Ù† Ø§Ù„Ù‚ØªØ§Ù„ Ø¥Ù„Ù‰ Ø¥ÙŠØ·Ø§Ù„ÙŠØ§ØŸØ§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù‚Ø°ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø© Ø±Ø®ÙŠØµØ© ØªÙƒÙˆÙ† Ø³Ø¹ÙŠØ¯Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø§Ù„\n Ø±ÙŠÙ†Ø¬Ùˆ: ÙŠØ§ Ø³ÙˆØ¨Ø± Ø«ÙƒØ³ ÙƒØ«ÙŠØ±Ø§ !!!\nÙ„Ø§ ÙŠØ¹Ø±Ù Ø±ÙŠÙ†Ø¬Ùˆ Ù…Ø§ ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ ØµØ¯ÙŠÙ‚ØªÙ‡ ØŒ Ø³ÙŠÙ„ÙŠØ§ ØŒ Ù„Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯.Ø³ÙŠÙ„ÙŠØ§ Ù‡ÙŠ Ø£Ø®Øª ÙˆÙŠÙ†ØªÙˆÙ†.ÙŠÙ‚ØªØ±Ø­ Ù„ÙŠÙ† Ø´ÙŠØ¦Ù‹Ø§ Ù…Ù† Ø§ÙŠÙƒÙŠØ§ Ø£Ùˆ Ø±Ø­Ù„Ø© Ø±Ø®ÙŠØµØ© Ø¥Ù„Ù‰ Ø¥ÙŠØ·Ø§Ù„ÙŠØ§.\n","output_type":"stream"}]},{"cell_type":"code","source":"w=a.merge_and_unload() ","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:48:39.767637Z","iopub.execute_input":"2023-09-14T13:48:39.768094Z","iopub.status.idle":"2023-09-14T13:48:43.453923Z","shell.execute_reply.started":"2023-09-14T13:48:39.768059Z","shell.execute_reply":"2023-09-14T13:48:43.452874Z"},"editable":false,"trusted":true},"execution_count":136,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:205: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:04:39.439383Z","iopub.execute_input":"2023-09-14T14:04:39.440229Z","iopub.status.idle":"2023-09-14T14:04:39.453536Z","shell.execute_reply.started":"2023-09-14T14:04:39.440197Z","shell.execute_reply":"2023-09-14T14:04:39.452483Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"editable":false,"trusted":true},"execution_count":178,"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"BloomForCausalLM(\n  (transformer): BloomModel(\n    (word_embeddings): Embedding(250880, 2560)\n    (word_embeddings_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n    (h): ModuleList(\n      (0-29): 30 x BloomBlock(\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (self_attention): BloomAttention(\n          (query_key_value): Linear4bit(in_features=2560, out_features=7680, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (attention_dropout): Dropout(p=0.0, inplace=False)\n        )\n        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (mlp): BloomMLP(\n          (dense_h_to_4h): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (gelu_impl): BloomGelu()\n          (dense_4h_to_h): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n      )\n    )\n    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=250880, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:30:30.355669Z","iopub.execute_input":"2023-09-14T14:30:30.356112Z","iopub.status.idle":"2023-09-14T14:30:30.388384Z","shell.execute_reply.started":"2023-09-14T14:30:30.356078Z","shell.execute_reply":"2023-09-14T14:30:30.387476Z"},"editable":false,"trusted":true},"execution_count":182,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b9e38a7270d4386a94e487bce2b8da3"}},"metadata":{}}]},{"cell_type":"code","source":"torch.save(w.state_dict(),\"bloom_weights.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:38:21.258142Z","iopub.execute_input":"2023-09-14T14:38:21.258733Z","iopub.status.idle":"2023-09-14T14:38:27.615725Z","shell.execute_reply.started":"2023-09-14T14:38:21.258700Z","shell.execute_reply":"2023-09-14T14:38:27.614421Z"},"editable":false,"trusted":true},"execution_count":187,"outputs":[]},{"cell_type":"code","source":"w.push_to_hub(\"mohamedemam/Arabic-meeting-summarization\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:57:47.727140Z","iopub.execute_input":"2023-09-14T14:57:47.727574Z","iopub.status.idle":"2023-09-14T14:57:48.195322Z","shell.execute_reply.started":"2023-09-14T14:57:47.727543Z","shell.execute_reply":"2023-09-14T14:57:48.194047Z"},"editable":false,"trusted":true},"execution_count":189,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[189], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmohamedemam/Arabic-meeting-summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:893\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(work_dir)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Save all files.\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_modified_files(\n\u001b[1;32m    896\u001b[0m     work_dir,\n\u001b[1;32m    897\u001b[0m     repo_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    903\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1868\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1862\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` to a 8-bit converted model you may likely encounter unexepected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m behaviors. If you want to save 8-bit models, make sure to have `bitsandbytes>0.37.2` installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1865\u001b[0m     )\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1870\u001b[0m     )\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1873\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1875\u001b[0m     )\n","\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"],"ename":"NotImplementedError","evalue":"You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported","output_type":"error"}]},{"cell_type":"code","source":"huggingface_hub.(\"mohamedemam/Arabic-meeting-summarization\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:34:58.232187Z","iopub.execute_input":"2023-09-14T14:34:58.232570Z","iopub.status.idle":"2023-09-14T14:34:58.439671Z","shell.execute_reply.started":"2023-09-14T14:34:58.232540Z","shell.execute_reply":"2023-09-14T14:34:58.437810Z"},"editable":false,"trusted":true},"execution_count":185,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmohamedemam/Arabic-meeting-summarization\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:893\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m files_timestamps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_files_timestamps(work_dir)\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# Save all files.\u001b[39;00m\n\u001b[0;32m--> 893\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_serialization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_modified_files(\n\u001b[1;32m    896\u001b[0m     work_dir,\n\u001b[1;32m    897\u001b[0m     repo_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    903\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:1868\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1862\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` to a 8-bit converted model you may likely encounter unexepected\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m behaviors. If you want to save 8-bit models, make sure to have `bitsandbytes>0.37.2` installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1865\u001b[0m     )\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 1868\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1869\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are calling `save_pretrained` on a 4-bit converted model. This is currently not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1870\u001b[0m     )\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1873\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1874\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_config` is deprecated and will be removed in v5 of Transformers. Use `is_main_process` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1875\u001b[0m     )\n","\u001b[0;31mNotImplementedError\u001b[0m: You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported"],"ename":"NotImplementedError","evalue":"You are calling `save_pretrained` on a 4-bit converted model. This is currently not supported","output_type":"error"}]},{"cell_type":"code","source":"output_tokens = a.generate(**dataset_test[153], max_new_tokens=50,do_sample=True,num_return_sequences=4 , num_beams=6 ,temperature=.8, top_p=0.9\n                          )\nfor i in tokenizer.batch_decode(output_tokens,skip_special_tokens=True):\n            print(i)\n            print(\"end\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T14:26:04.152339Z","iopub.execute_input":"2023-09-14T14:26:04.153432Z","iopub.status.idle":"2023-09-14T14:26:08.652879Z","shell.execute_reply.started":"2023-09-14T14:26:04.153384Z","shell.execute_reply":"2023-09-14T14:26:08.651913Z"},"editable":false,"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"Ø§Ù„Ø´Ø®Øµ 1: ÙŠØ§ Ù„Ù‡Ø§ Ù…Ù† Ø¨Ù„ÙˆØ²Ø© Ø¬Ø°Ø§Ø¨Ø© ØŒ ØªØ¨Ø¯Ùˆ Ø¬Ù…ÙŠÙ„Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† Ø§Ù„Ø£Ø²Ø±Ù‚!\n  Ø§Ù„Ø´Ø®Øµ 2: Ø­Ù‚Ø§ØŸØ´ÙƒØ±Ù‹Ø§ Ù„Ùƒ.Ø§Ø´ØªØ±ÙŠØªÙ‡Ø§ ÙÙŠ Ø´Ø§Ø±Ø¹ Ø³Ø¨Ø±ÙŠÙ†Øº Ø£Ù…Ø³.\n  Ø§Ù„Ø´Ø®Øµ 1: Ø¥Ù†Ù‡ Ù„Ø·ÙŠÙ Ù„Ù„ØºØ§ÙŠØ©.ÙŠØ³ÙŠØ± Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù… Ù…Ø¹ ØªÙ†ÙˆØ±ØªÙƒ.\n  Ø§Ù„Ø´Ø®Øµ 2: Ø´ÙƒØ±Ø§ Ù„Ùƒ.Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ Ø¬Ø¯Ù‹Ø§ Ù…Ù†Ùƒ Ø£Ù† ØªÙ‚ÙˆÙ„ Ø°Ù„Ùƒ.\n  Ø§Ù„Ø´Ø®Øµ 1: Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚.Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† ÙŠØ¸Ù‡Ø± Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø°ÙˆÙ‚Ùƒ Ø§Ù„Ø¬ÙŠØ¯.\n  Ø§Ù„Ø´Ø®Øµ 2: Ù‡Ø°Ø§ Ù…Ø¬Ø§Ù…Ù„Ø© Ù‚Ø§Ø¯Ù…Ø© Ù…Ù†Ùƒ.\n\nSummarize the previous text in three sentences in arabic:\n\nÙŠØ·Ù„Ø¨ Ø´Ø®Øµ Ù…Ù† Ø´Ø®Øµ Ø¢Ø®Ø± Ø´Ø±Ø§Ø¡ ÙØ³ØªØ§Ù†.\nend\nØ§Ù„Ø´Ø®Øµ 1: ÙŠØ§ Ù„Ù‡Ø§ Ù…Ù† Ø¨Ù„ÙˆØ²Ø© Ø¬Ø°Ø§Ø¨Ø© ØŒ ØªØ¨Ø¯Ùˆ Ø¬Ù…ÙŠÙ„Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† Ø§Ù„Ø£Ø²Ø±Ù‚!\n  Ø§Ù„Ø´Ø®Øµ 2: Ø­Ù‚Ø§ØŸØ´ÙƒØ±Ù‹Ø§ Ù„Ùƒ.Ø§Ø´ØªØ±ÙŠØªÙ‡Ø§ ÙÙŠ Ø´Ø§Ø±Ø¹ Ø³Ø¨Ø±ÙŠÙ†Øº Ø£Ù…Ø³.\n  Ø§Ù„Ø´Ø®Øµ 1: Ø¥Ù†Ù‡ Ù„Ø·ÙŠÙ Ù„Ù„ØºØ§ÙŠØ©.ÙŠØ³ÙŠØ± Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù… Ù…Ø¹ ØªÙ†ÙˆØ±ØªÙƒ.\n  Ø§Ù„Ø´Ø®Øµ 2: Ø´ÙƒØ±Ø§ Ù„Ùƒ.Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ Ø¬Ø¯Ù‹Ø§ Ù…Ù†Ùƒ Ø£Ù† ØªÙ‚ÙˆÙ„ Ø°Ù„Ùƒ.\n  Ø§Ù„Ø´Ø®Øµ 1: Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚.Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† ÙŠØ¸Ù‡Ø± Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø°ÙˆÙ‚Ùƒ Ø§Ù„Ø¬ÙŠØ¯.\n  Ø§Ù„Ø´Ø®Øµ 2: Ù‡Ø°Ø§ Ù…Ø¬Ø§Ù…Ù„Ø© Ù‚Ø§Ø¯Ù…Ø© Ù…Ù†Ùƒ.\n\nSummarize the previous text in three sentences in arabic:\n\nÙŠØ·Ù„Ø¨ Ø´Ø®Øµ Ù…Ù† Ø´Ø®Øµ Ø¢Ø®Ø± Ø´Ø±Ø§Ø¡ ÙØ³ØªØ§Ù† Ù„Ù‡.\nend\nØ§Ù„Ø´Ø®Øµ 1: ÙŠØ§ Ù„Ù‡Ø§ Ù…Ù† Ø¨Ù„ÙˆØ²Ø© Ø¬Ø°Ø§Ø¨Ø© ØŒ ØªØ¨Ø¯Ùˆ Ø¬Ù…ÙŠÙ„Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† Ø§Ù„Ø£Ø²Ø±Ù‚!\n  Ø§Ù„Ø´Ø®Øµ 2: Ø­Ù‚Ø§ØŸØ´ÙƒØ±Ù‹Ø§ Ù„Ùƒ.Ø§Ø´ØªØ±ÙŠØªÙ‡Ø§ ÙÙŠ Ø´Ø§Ø±Ø¹ Ø³Ø¨Ø±ÙŠÙ†Øº Ø£Ù…Ø³.\n  Ø§Ù„Ø´Ø®Øµ 1: Ø¥Ù†Ù‡ Ù„Ø·ÙŠÙ Ù„Ù„ØºØ§ÙŠØ©.ÙŠØ³ÙŠØ± Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù… Ù…Ø¹ ØªÙ†ÙˆØ±ØªÙƒ.\n  Ø§Ù„Ø´Ø®Øµ 2: Ø´ÙƒØ±Ø§ Ù„Ùƒ.Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ Ø¬Ø¯Ù‹Ø§ Ù…Ù†Ùƒ Ø£Ù† ØªÙ‚ÙˆÙ„ Ø°Ù„Ùƒ.\n  Ø§Ù„Ø´Ø®Øµ 1: Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚.Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† ÙŠØ¸Ù‡Ø± Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø°ÙˆÙ‚Ùƒ Ø§Ù„Ø¬ÙŠØ¯.\n  Ø§Ù„Ø´Ø®Øµ 2: Ù‡Ø°Ø§ Ù…Ø¬Ø§Ù…Ù„Ø© Ù‚Ø§Ø¯Ù…Ø© Ù…Ù†Ùƒ.\n\nSummarize the previous text in three sentences in arabic:\n\nÙŠØ·Ù„Ø¨ Ø´Ø®Øµ Ù…Ù† Ø´Ø®Øµ Ø¢Ø®Ø± Ø£Ù† ÙŠØ«Ù†ÙŠ Ø¹Ù„ÙŠÙ‡.\nend\nØ§Ù„Ø´Ø®Øµ 1: ÙŠØ§ Ù„Ù‡Ø§ Ù…Ù† Ø¨Ù„ÙˆØ²Ø© Ø¬Ø°Ø§Ø¨Ø© ØŒ ØªØ¨Ø¯Ùˆ Ø¬Ù…ÙŠÙ„Ù‹Ø§ Ø¬Ø¯Ù‹Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† Ø§Ù„Ø£Ø²Ø±Ù‚!\n  Ø§Ù„Ø´Ø®Øµ 2: Ø­Ù‚Ø§ØŸØ´ÙƒØ±Ù‹Ø§ Ù„Ùƒ.Ø§Ø´ØªØ±ÙŠØªÙ‡Ø§ ÙÙŠ Ø´Ø§Ø±Ø¹ Ø³Ø¨Ø±ÙŠÙ†Øº Ø£Ù…Ø³.\n  Ø§Ù„Ø´Ø®Øµ 1: Ø¥Ù†Ù‡ Ù„Ø·ÙŠÙ Ù„Ù„ØºØ§ÙŠØ©.ÙŠØ³ÙŠØ± Ø¹Ù„Ù‰ Ù…Ø§ ÙŠØ±Ø§Ù… Ù…Ø¹ ØªÙ†ÙˆØ±ØªÙƒ.\n  Ø§Ù„Ø´Ø®Øµ 2: Ø´ÙƒØ±Ø§ Ù„Ùƒ.Ù…Ù† Ø§Ù„Ø¬ÙŠØ¯ Ø¬Ø¯Ù‹Ø§ Ù…Ù†Ùƒ Ø£Ù† ØªÙ‚ÙˆÙ„ Ø°Ù„Ùƒ.\n  Ø§Ù„Ø´Ø®Øµ 1: Ù„ÙŠØ³ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø·Ù„Ø§Ù‚.Ù‡Ø°Ø§ Ø§Ù„ÙØ³ØªØ§Ù† ÙŠØ¸Ù‡Ø± Ø¨Ø§Ù„ØªØ£ÙƒÙŠØ¯ Ø°ÙˆÙ‚Ùƒ Ø§Ù„Ø¬ÙŠØ¯.\n  Ø§Ù„Ø´Ø®Øµ 2: Ù‡Ø°Ø§ Ù…Ø¬Ø§Ù…Ù„Ø© Ù‚Ø§Ø¯Ù…Ø© Ù…Ù†Ùƒ.\n\nSummarize the previous text in three sentences in arabic:\n\nÙŠØ·Ù„Ø¨ Ø´Ø®Øµ Ù…Ù† Ø´Ø®Øµ Ø¢Ø®Ø± Ø´Ø±Ø§Ø¡ ÙØ³ØªØ§Ù† Ø²Ù‡Ø±ÙŠ.\nend\n","output_type":"stream"}]},{"cell_type":"code","source":"output_tokens = a.generate(**dataset_train[23007], max_new_tokens=50,top_p=.4,do_sample=True,num_return_sequences=4 , num_beams=4,temperature =1.5)\nfor i in tokenizer.batch_decode(output_tokens,skip_special_tokens=True):\n            print(i)\n            print(\"end\")","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:43.257219Z","iopub.execute_input":"2023-09-14T13:52:43.257629Z","iopub.status.idle":"2023-09-14T13:52:43.341232Z","shell.execute_reply.started":"2023-09-14T13:52:43.257595Z","shell.execute_reply":"2023-09-14T13:52:43.340014Z"},"editable":false,"trusted":true},"execution_count":157,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[157], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mdataset_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m23007\u001b[39;49m\u001b[43m]\u001b[49m, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.4\u001b[39m,do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m , num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,temperature \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(output_tokens,skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;28mprint\u001b[39m(i)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:17:53.345615Z","iopub.execute_input":"2023-09-14T13:17:53.346019Z","iopub.status.idle":"2023-09-14T13:17:53.350644Z","shell.execute_reply.started":"2023-09-14T13:17:53.345968Z","shell.execute_reply":"2023-09-14T13:17:53.349673Z"},"editable":false,"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import  random_split","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:17:53.592554Z","iopub.execute_input":"2023-09-14T13:17:53.593163Z","iopub.status.idle":"2023-09-14T13:17:53.597983Z","shell.execute_reply.started":"2023-09-14T13:17:53.593128Z","shell.execute_reply":"2023-09-14T13:17:53.597019Z"},"editable":false,"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"dataset_train,dataset_valid,dataset_test=random_split(dataset_train,[.85,.075,.075])","metadata":{"execution":{"iopub.status.busy":"2023-09-14T13:52:34.993282Z","iopub.execute_input":"2023-09-14T13:52:34.993649Z","iopub.status.idle":"2023-09-14T13:52:35.000464Z","shell.execute_reply.started":"2023-09-14T13:52:34.993620Z","shell.execute_reply":"2023-09-14T13:52:34.999359Z"},"editable":false,"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.532213Z","iopub.execute_input":"2023-09-13T18:37:26.533162Z","iopub.status.idle":"2023-09-13T18:37:26.539279Z","shell.execute_reply.started":"2023-09-13T18:37:26.533129Z","shell.execute_reply":"2023-09-13T18:37:26.538380Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.enable_input_require_grads()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.540585Z","iopub.execute_input":"2023-09-13T18:37:26.541134Z","iopub.status.idle":"2023-09-13T18:37:26.553674Z","shell.execute_reply.started":"2023-09-13T18:37:26.541102Z","shell.execute_reply":"2023-09-13T18:37:26.552779Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.555043Z","iopub.execute_input":"2023-09-13T18:37:26.555431Z","iopub.status.idle":"2023-09-13T18:37:30.562194Z","shell.execute_reply.started":"2023-09-13T18:37:26.555401Z","shell.execute_reply":"2023-09-13T18:37:30.561265Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = TrainingArguments(\n    output_dir=\"./results_modified\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=26,\n    save_steps=200,\n    learning_rate=2e-5,\n            fp16=True\n,\n    weight_decay=0.001,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"constant\",\n)\ntrainer = Trainer(\n    model=model,\n    args=train_params,\n    train_dataset=dataset_train,\n    eval_dataset=dataset_valid\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:30.563544Z","iopub.execute_input":"2023-09-13T18:37:30.564435Z","iopub.status.idle":"2023-09-13T18:37:32.422972Z","shell.execute_reply.started":"2023-09-13T18:37:30.564394Z","shell.execute_reply":"2023-09-13T18:37:32.421990Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load(\"/kaggle/working/bloom_weights.pth\")","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:32.424182Z","iopub.execute_input":"2023-09-13T18:37:32.424905Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'bloomz.pt')","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}