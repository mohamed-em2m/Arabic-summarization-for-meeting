{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-13T18:33:37.316082Z","iopub.execute_input":"2023-09-13T18:33:37.316408Z","iopub.status.idle":"2023-09-13T18:33:37.669350Z","shell.execute_reply.started":"2023-09-13T18:33:37.316370Z","shell.execute_reply":"2023-09-13T18:33:37.668407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install  -U bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:33:37.671478Z","iopub.execute_input":"2023-09-13T18:33:37.671998Z","iopub.status.idle":"2023-09-13T18:33:55.417668Z","shell.execute_reply.started":"2023-09-13T18:33:37.671963Z","shell.execute_reply":"2023-09-13T18:33:55.416233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/transformers.git ","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:33:55.420430Z","iopub.execute_input":"2023-09-13T18:33:55.421589Z","iopub.status.idle":"2023-09-13T18:34:46.342578Z","shell.execute_reply.started":"2023-09-13T18:33:55.421550Z","shell.execute_reply":"2023-09-13T18:34:46.341171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install  -U git+https://github.com/huggingface/peft.git\n!pip install  -U git+https://github.com/huggingface/accelerate.git\n!pip install  datasets","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:34:46.345957Z","iopub.execute_input":"2023-09-13T18:34:46.346417Z","iopub.status.idle":"2023-09-13T18:35:53.839435Z","shell.execute_reply.started":"2023-09-13T18:34:46.346299Z","shell.execute_reply":"2023-09-13T18:35:53.838300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:35:53.841499Z","iopub.execute_input":"2023-09-13T18:35:53.842140Z","iopub.status.idle":"2023-09-13T18:35:57.231245Z","shell.execute_reply.started":"2023-09-13T18:35:53.842099Z","shell.execute_reply":"2023-09-13T18:35:57.230254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import BitsAndBytesConfig\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-3b\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigscience/bloomz-3b\",quantization_config=nf4_config,)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:35:57.232618Z","iopub.execute_input":"2023-09-13T18:35:57.233114Z","iopub.status.idle":"2023-09-13T18:37:01.206996Z","shell.execute_reply.started":"2023-09-13T18:35:57.233084Z","shell.execute_reply":"2023-09-13T18:37:01.206018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install peft","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:01.208280Z","iopub.execute_input":"2023-09-13T18:37:01.209068Z","iopub.status.idle":"2023-09-13T18:37:13.643996Z","shell.execute_reply.started":"2023-09-13T18:37:01.209031Z","shell.execute_reply":"2023-09-13T18:37:13.642817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=4, \n    lora_alpha=16, \n            target_modules=[\"query_key_value\"],\n\n    lora_dropout=0.05, \n    bias=\"none\", \n    \n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:13.646572Z","iopub.execute_input":"2023-09-13T18:37:13.647753Z","iopub.status.idle":"2023-09-13T18:37:18.743246Z","shell.execute_reply.started":"2023-09-13T18:37:13.647714Z","shell.execute_reply":"2023-09-13T18:37:18.742273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/arabic-samsum-dialogsum/arabic_dialog.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:18.744635Z","iopub.execute_input":"2023-09-13T18:37:18.745072Z","iopub.status.idle":"2023-09-13T18:37:19.528909Z","shell.execute_reply.started":"2023-09-13T18:37:18.745040Z","shell.execute_reply":"2023-09-13T18:37:19.527958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:19.533369Z","iopub.execute_input":"2023-09-13T18:37:19.533662Z","iopub.status.idle":"2023-09-13T18:37:19.538382Z","shell.execute_reply.started":"2023-09-13T18:37:19.533637Z","shell.execute_reply":"2023-09-13T18:37:19.537154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        a = tokenizer( (data['dialogue']+data['summary']).tolist(), truncation=True, padding='max_length', return_tensors=\"pt\", max_length=512)\n        self.dataset=  [\n            {\n            \n                            \"input_ids\":inputs,\n                            \"attention_mask\": att,\n                            \"labels\":inputs\n                        } \n                            for inputs,att in zip(a['input_ids'],a['attention_mask'])\n        ]\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        return self.dataset[idx]\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:19.540054Z","iopub.execute_input":"2023-09-13T18:37:19.540795Z","iopub.status.idle":"2023-09-13T18:37:19.553152Z","shell.execute_reply.started":"2023-09-13T18:37:19.540761Z","shell.execute_reply":"2023-09-13T18:37:19.552101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SummarizationDataset(Dataset):\n    def __init__(self, tokenized_dataset):\n        self.dialogue = tokenized_dataset['dialogue']\n        self.summary = tokenized_dataset['summary']\n        self.tokenized_dataset=tokenized_dataset\n    def __len__(self):\n        return len(self.tokenized_dataset)\n\n    def __getitem__(self, idx):\n        a=tokenizer(self.dialogue[idx] +f\"\\n\\nSummarize the previous text in three sentences:\\n\\n\"+self.summary[idx], truncation=True, padding='max_length', return_tensors=\"pt\", max_length=512)\n        return {\n            \n                        \"input_ids\": a[\"input_ids\"][0],\n            \"attention_mask\": a[\"attention_mask\"][0],\n            \"labels\":a['input_ids'][0]\n        }","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:19.554640Z","iopub.execute_input":"2023-09-13T18:37:19.555165Z","iopub.status.idle":"2023-09-13T18:37:19.564296Z","shell.execute_reply.started":"2023-09-13T18:37:19.555132Z","shell.execute_reply":"2023-09-13T18:37:19.563326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train=SummarizationDataset(data)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:19.567388Z","iopub.execute_input":"2023-09-13T18:37:19.567671Z","iopub.status.idle":"2023-09-13T18:37:19.581554Z","shell.execute_reply.started":"2023-09-13T18:37:19.567648Z","shell.execute_reply":"2023-09-13T18:37:19.580609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:19.582752Z","iopub.execute_input":"2023-09-13T18:37:19.583363Z","iopub.status.idle":"2023-09-13T18:37:26.505312Z","shell.execute_reply.started":"2023-09-13T18:37:19.583315Z","shell.execute_reply":"2023-09-13T18:37:26.504399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import  random_split","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.506590Z","iopub.execute_input":"2023-09-13T18:37:26.507308Z","iopub.status.idle":"2023-09-13T18:37:26.512834Z","shell.execute_reply.started":"2023-09-13T18:37:26.507272Z","shell.execute_reply":"2023-09-13T18:37:26.511749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train,dataset_valid,dataset_test=random_split(dataset_train,[.85,.075,.075])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.514175Z","iopub.execute_input":"2023-09-13T18:37:26.514748Z","iopub.status.idle":"2023-09-13T18:37:26.530954Z","shell.execute_reply.started":"2023-09-13T18:37:26.514714Z","shell.execute_reply":"2023-09-13T18:37:26.530051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.532213Z","iopub.execute_input":"2023-09-13T18:37:26.533162Z","iopub.status.idle":"2023-09-13T18:37:26.539279Z","shell.execute_reply.started":"2023-09-13T18:37:26.533129Z","shell.execute_reply":"2023-09-13T18:37:26.538380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.enable_input_require_grads()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.540585Z","iopub.execute_input":"2023-09-13T18:37:26.541134Z","iopub.status.idle":"2023-09-13T18:37:26.553674Z","shell.execute_reply.started":"2023-09-13T18:37:26.541102Z","shell.execute_reply":"2023-09-13T18:37:26.552779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:26.555043Z","iopub.execute_input":"2023-09-13T18:37:26.555431Z","iopub.status.idle":"2023-09-13T18:37:30.562194Z","shell.execute_reply.started":"2023-09-13T18:37:26.555401Z","shell.execute_reply":"2023-09-13T18:37:30.561265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_params = TrainingArguments(\n    output_dir=\"./results_modified\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=26,\n    save_steps=200,\n    learning_rate=2e-5,\n            fp16=True\n,\n    weight_decay=0.001,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"constant\",\n)\ntrainer = Trainer(\n    model=model,\n    args=train_params,\n    train_dataset=dataset_train,\n    eval_dataset=dataset_valid\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:30.563544Z","iopub.execute_input":"2023-09-13T18:37:30.564435Z","iopub.status.idle":"2023-09-13T18:37:32.422972Z","shell.execute_reply.started":"2023-09-13T18:37:30.564394Z","shell.execute_reply":"2023-09-13T18:37:32.421990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T18:37:32.424182Z","iopub.execute_input":"2023-09-13T18:37:32.424905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'bloomz.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}